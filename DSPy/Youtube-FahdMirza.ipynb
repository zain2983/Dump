{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=Jfpxjg8xj9w"
      ],
      "metadata": {
        "id": "lsh2klst_CVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dspy-ai lamini rich"
      ],
      "metadata": {
        "id": "VuJ2Bqwg05kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import dspy\n",
        "from dspy.datasets import HotPotQA\n",
        "from dspy.teleprompt import BootstrapFewShot\n",
        "from dspy.evaluate.evaluate import Evaluate\n",
        "from dsp.utils import deduplicate\n",
        "from rich import print\n",
        "from dsp import LM\n",
        "import lamini\n",
        "from dspy.datasets import HotPotQA\n",
        "import dspy\n",
        "from dspy.evaluate.evaluate import Evaluate\n",
        "# from dspy.teleprompt import bootstrapFewShot"
      ],
      "metadata": {
        "id": "z8o9PcuG07Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
        "\n",
        "# Set up the LM.\n",
        "turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=250)\n",
        "dspy.settings.configure(lm=turbo)\n",
        "\n",
        "# Load math questions from the GSM8K dataset.\n",
        "gsm8k = GSM8K()\n",
        "gsm8k_trainset, gsm8k_devset = gsm8k.train[:10], gsm8k.dev[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "add45646c59b41b6ac016957a46fe2c9",
            "73f6c250b190421b9ffa174c816f6dc3",
            "7a7b35bb6ded46ffa0575f6f2065e090",
            "01dc72d9e6434d0a908666063e5a4ea7",
            "2045ece460004898882dcc75cf48a83f",
            "e7c01e0d57524926b551af45c37d9722",
            "1ecb548f14604f479ae76fda71fc6d2b",
            "f31398f1dee3436bb4dcb55ede55cff1",
            "32481c1aaa7f4d8d9ef739f0d0e32fa9",
            "897b6517e2f240ee97f581fccead9373",
            "62740a570c5e42faa5235770d19f3f8a",
            "3cbb54a46b45475980b4817402f204af",
            "02f656bdc01249c7b3b43ab8604c80f4",
            "fb254165fc0f48a28d8e2413c188654f",
            "9a4c5bfbf0f5451c8e58ae38c530612c",
            "17cd948b709543a791614dba3e151579",
            "bdcd6e476d55460ca3bed56e585f1e49",
            "4797ec5947ef43f68491780a489d4c52",
            "97dd598e94fd4a96adf40822d83e8ce4",
            "1f58e6e17aca4a30ae0999787e29079a",
            "be12fcaec0074747a5b617be0e6aecd6",
            "890af75413f14383829fda2a0e8f73d7",
            "446ec0dc90f14affa2f14626ff1ea2c7",
            "921a0866d6094289b8857552c9259624",
            "06bd894cf7eb4ed4bc05f04baecf5679",
            "54840f4f7f554d7a996687053180fb15",
            "32977d3ddd8f49d4aa996e3690807a50",
            "ae592d77467449828ccfa945f4257204",
            "ea0297dbdab44770b84bf2925dbe2e9f",
            "8eb7ade7f0cc4ecaa1fbed94e57397fb",
            "609ca840310546a9b7d9697e30753e12",
            "27ef1e21454845c29a35279f7ba12fd9",
            "8c1f2959dc484550aab2446f8b5aab7c",
            "e73aa00bbf224142b1a4a56860a9429b",
            "1f6eaf9d759c4252aa167aec887c4e68",
            "9b76a24607b44cd48dcc8f83cf4a94cb",
            "f60262f70b744f3bb0d4ed08a78657c6",
            "beda208e6a014a8dbb52c0bea49062ed",
            "9e3c9276fb2d4ac8adb9b3288d9ef3f1",
            "43ae91cf26dd4f2f8dcd16fa3e7fcbeb",
            "e42b7d12a6804e45a1e92ac6ef1dc7af",
            "91230f52c45b40e787fd5cf5d2654768",
            "f4378516e73c43229a98bf356c6b36cb",
            "2686d876aa8f4129b012e0de3dbf82af",
            "d77204f2feaf4ed5becdaf0851d69979",
            "0450ae8ee6d84a37b4bf56b0ef746976",
            "370ea534c526454d9c2e50e9b8e64e05",
            "6124e5f2e2684cb595c843007054644d",
            "c54a023977874db3b45089308645070d",
            "5ddf8a1ae5f34ad5be29bc65044afdc7",
            "79c0a44c60a4458fad8ae6dd508bae2b",
            "91cb2b83bdd84b4f994d1e0e21fff5f4",
            "2ebc68ad1dd144e1a5c10c6586ccdbe2",
            "3b62208179c9477f826cd261786c579f",
            "1a2e9939d43f4f1a86e1ac1a3894b650"
          ]
        },
        "id": "d-j8Iti67_QN",
        "outputId": "3b6231a5-59b7-49c8-df3a-cfc18b0550a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "add45646c59b41b6ac016957a46fe2c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cbb54a46b45475980b4817402f204af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "446ec0dc90f14affa2f14626ff1ea2c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e73aa00bbf224142b1a4a56860a9429b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d77204f2feaf4ed5becdaf0851d69979"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7473/7473 [00:00<00:00, 19803.09it/s]\n",
            "100%|██████████| 1319/1319 [00:00<00:00, 18235.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dspy-ai"
      ],
      "metadata": {
        "id": "jhDFDSgkxmRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "import time\n",
        "class CustomLMClient(LM):\n",
        "    def __init__(self):\n",
        "        self.provider = \"lamini\"\n",
        "        self.history = []\n",
        "        lamini.api_key = \"030f9952a4ee130a33d4fcfd7a7f3dbeab6b2a24a46917b6681019267130e468\"\n",
        "        self.llm = lamini.Lamini(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "        # Add a kwargs attribute to store keyword arguments\n",
        "        self.kwargs = {'temperature' : 0.7 , 'max_tokens': 100}\n",
        "\n",
        "    def basic_request(self, prompt, **kwargs):\n",
        "        # Call the lamini API to generate a response\n",
        "        print(\"$ API Request sent\")\n",
        "        response = self.llm.generate(prompt)\n",
        "        return response\n",
        "\n",
        "    def __call__(self, prompt, only_completed=True, return_sorted=False, **kwargs):\n",
        "        # Add the prompt to the history\n",
        "        self.history.append(prompt)\n",
        "\n",
        "        # Get the response using the basic_request method\n",
        "        response = self.basic_request(prompt)\n",
        "\n",
        "        # Return the response\n",
        "        return response\n",
        "\n",
        "custom_lm = CustomLMClient()\n",
        "\n",
        "# Configure dspy to use your custom LLM\n",
        "dspy.settings.configure(lm=custom_lm)"
      ],
      "metadata": {
        "id": "nHefqplNym5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShakespeareanTranslation(dspy.Signature):\n",
        "    \"\"\"Translate simple english to Shakespearean english.\"\"\"\n",
        "    simple_english = dspy.InputField()\n",
        "    # print(simple_english)\n",
        "    shakespearean_english = dspy.OutputField()\n",
        "    # print(shakespearean_english)"
      ],
      "metadata": {
        "id": "4GAfXiS8x0lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "# turbo = dspy.OpenAI(model='gpt-3.5-turbo', max_tokens=1000, api_key=OPENAI_API_KEY)\n",
        "dspy.settings.configure(lm=custom_lm)\n",
        "from dspy.signatures.signature import signature_to_template\n",
        "shakespeare_translation_as_template = signature_to_template(ShakespeareanTranslation)"
      ],
      "metadata": {
        "id": "H-z0RGiGx2Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CoT(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prog = dspy.ChainOfThought(ShakespeareanTranslation)\n",
        "\n",
        "    def forward(self, simple_english):\n",
        "        return self.prog(simple_english=simple_english)\n",
        "c = CoT()"
      ],
      "metadata": {
        "id": "BsNO9W-0x3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.forward(\"You should relax and have fun while it lasts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "hWje9mg8x3_p",
        "outputId": "925d1195-4255-4ec3-8cb6-234eeb8e0245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "$ API Request sent\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">$ API Request sent\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "$ API Request sent\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">$ API Request sent\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    rationale='e',\n",
              "    shakespearean_english='E',\n",
              "    completions=Completions(...)\n",
              ") (2547 completions omitted)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}